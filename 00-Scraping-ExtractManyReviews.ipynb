{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/icon_important.jpg\" width=\"50\" align=\"left\"/>\n",
    "</div>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __Important Legal Notice__\n",
    "By running and editing this Jupyter notebook with the corresponding dataset, you agree that you will not use or store the data for other purposes than participating in the Champagne Coding with DNB & Women in Data Science, Oslo. You will delete the data and notebook after the event and will not attempt to identify any of the commentors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "current_directory = Path.cwd()\n",
    "reviews_directory = Path(current_directory, 'reviews')\n",
    "html_directory = Path(current_directory, 'html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import requests\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_to_crawl = {\n",
    "    \n",
    "}\n",
    "\n",
    "apps_to_crawl['nordea'] = 'no.nordea.mobilebank&hl=en'\n",
    "apps_to_crawl['dnb'] = 'no.apps.dnbnor&hl=en'\n",
    "apps_to_crawl['sparebank'] = 'no.sparebank1.mobilbank&hl=en'\n",
    "apps_to_crawl['sbanken'] = 'no.skandiabanken&hl=en'\n",
    "apps_to_crawl['posten'] = 'no.posten.sporing.controller&hl=en'\n",
    "apps_to_crawl['aftenposten'] = 'no.cita&hl=en'\n",
    "apps_to_crawl['nrk'] = 'no.nrk.mobil.app&hl=en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start crawling the webpage.\n",
    "\n",
    "Here we will open a new driver for each application and run a loop in the page - switching between scrolling and clicking. It will click if there is an element called ```Show More``` or we will scroll continuously if the element isn't present. The loop will only stop once the max number of clicks or the max number of scrolls has been reached.\n",
    "\n",
    "We will then find the different HTML elements to parse the reviews into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what we've found for parsing HTML elements of the reviews:\n",
    "- __Entire Review & Contents__: ```div jscontroller=\"H6eOGe\"```\n",
    "- __Name__: ```span class=\"X43Kjb\"```\n",
    "- __Date__: ```span class=\"p2TkOb\"```\n",
    "- __Review Score__: ```div class=\"pf5lIe\"```\n",
    "- __Review Text__: ```span jsname=\"fbQN7e\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app_name, app_id in apps_to_crawl.items():\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    \n",
    "    link = \"https://play.google.com/store/apps/details?id={}\".format(app_id)\n",
    "    driver.get(link + '&showAllReviews=true')\n",
    "\n",
    "    # Change this number to get more or less reviews\n",
    "    max_clicks = 20\n",
    "\n",
    "    # Start crawling\n",
    "    num_clicks = 0\n",
    "    num_scrolls = 0\n",
    "    while num_clicks <= max_clicks and num_scrolls <= max_clicks*5:\n",
    "        try:\n",
    "            show_more = driver.find_elements_by_xpath(\"//*[contains(text(), 'Show More')]\")\n",
    "            show_more[0].click()\n",
    "\n",
    "            num_clicks += 1\n",
    "        except:\n",
    "            html = driver.find_element_by_tag_name('html')\n",
    "            html.send_keys(Keys.END)\n",
    "            num_scrolls +=1\n",
    "            time.sleep(1)\n",
    "\n",
    "    print('Done scrolling')        \n",
    "\n",
    "    soup = bs4.BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    driver.close()\n",
    "\n",
    "    all_comments = soup.body.find_all('div', attrs={'jscontroller': 'H6eOGe'})\n",
    "\n",
    "    ### Loop through each of the comments and use a beautiful soup function to find the relevant parts\n",
    "    all_reviews_dict={}\n",
    "    i = 0\n",
    "\n",
    "    for each_comment in all_comments:    \n",
    "        current_review = {}\n",
    "\n",
    "        name = each_comment.find('span', attrs= {'class': 'X43Kjb'})\n",
    "        current_review['Name'] = name.text \n",
    "\n",
    "        date = each_comment.find('span', attrs= {'class': 'p2TkOb'})\n",
    "        current_review['Date'] = date.text \n",
    "\n",
    "        score = each_comment.find('div', attrs= {'class': 'pf5lIe'})\n",
    "        current_review['Review_Score'] = re.search('(\\d+) stars out of five stars', str(score)).group(1)\n",
    "\n",
    "        review_text = each_comment.find('span', attrs= {'jsname': 'bN97Pc'}) #jsname=\"bN97Pc\"\n",
    "        current_review['Review_Text'] = review_text.text\n",
    "        i += 1\n",
    "\n",
    "        all_reviews_dict[i] = current_review\n",
    "\n",
    "    df_allreviews = pd.DataFrame(all_reviews_dict)\n",
    "    df_allreviews = df_allreviews.T\n",
    "\n",
    "    df_allreviews.drop_duplicates(inplace=True)\n",
    "    print(\"Done reading {} application data.{} reviews were found.\"format(app_name, \n",
    "                                                                          len(df_allreviews))\n",
    "    \n",
    "    df_allreviews.to_csv(Path(reviews_directory, '{}_reviews.csv'.format(app_name)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
